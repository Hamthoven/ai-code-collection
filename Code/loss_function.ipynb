{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "\n",
    "## 1. 개요\n",
    "\n",
    "* 구현 내용: 손실 함수를 직접 구현합니다.\n",
    "* 코드 요약: 기초적인 손실 함수를 직접 구현해봅니다.\n",
    "* 참고 자료: <밑바닥부터 시작하는 딥러닝> 사이토 고키, 한빛미디어 (도서, 원제; Deep Learning from Scratch, O'REILLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차제곱합 함수: 오차가 작을 수록 결과값이 작은 함수 -> 얼마나 성능이 안좋은지를 측정 가능\n",
    "def sum_squares_error(y,t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 엔트로피 함수: 자연 로그의 형태를 띄는 손실함수\n",
    "# np.log1p를 통해 0에 무한대 값이 나오는 것을 방지합니다.\n",
    "def cross_entropy_error(y,t):\n",
    "    return -np.sum(t * np.log1p(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n",
      "-0.4700036292457356\n"
     ]
    }
   ],
   "source": [
    "# 소프트맥스, 교차 엔트로피 실험\n",
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "y = [0.1,0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "print(sum_squares_error(np.array(y),np.array(t)))\n",
    "print(cross_entropy_error(np.array(y),np.array(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5975\n",
      "-0.09531017980432487\n"
     ]
    }
   ],
   "source": [
    "# 소프트맥스, 교차 엔트로피 실험\n",
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "y = [0.1,0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "print(sum_squares_error(np.array(y),np.array(t)))\n",
    "print(cross_entropy_error(np.array(y),np.array(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실함수의 최소값 찾기를 위한 경사하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기울기 함수: 함수의 기울기를 구합니다. (경사하강법을 위한 기반)\n",
    "def numerical_gradient(f,x):\n",
    "    h = math.e -4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val-h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_test_function(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 8.]\n",
      "[-0.  4.]\n",
      "[ 6. -0.]\n"
     ]
    }
   ],
   "source": [
    "print(numerical_gradient(gradient_test_function, np.array([3.0,4.0])))\n",
    "print(numerical_gradient(gradient_test_function, np.array([0.0,2.0])))\n",
    "print(numerical_gradient(gradient_test_function, np.array([3.0,0.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사하강법: 손실함수의 최솟값을 찾아 최적의 매개변수를 찾아내는 것이 목적입니다.\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f,x)\n",
    "        x -= lr * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110819e-10,  8.14814382e-10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 경사하강법 실험\n",
    "init_x = np.array([-3.0,4.0])\n",
    "gradient_descent(gradient_test_function, init_x = init_x, lr = 0.1, step_num = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
