{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 Lite Interview Scripter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic GPT-2 model test\n",
    "- import necessary libraries\n",
    "- load gpt 2 tokenizer, preprocessor and model\n",
    "- text generation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q git+https://github.com/keras-team/keras-nlp.git@google-io-2023 tensorflow-text==2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import keras_nlp\n",
    "from tensorflow import keras\n",
    "from tensorflow.lite.python import interpreter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_base_en\")\n",
    "gpt2_preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
    "    \"gpt2_base_en\",\n",
    "    sequence_length=256,\n",
    "    add_end_token=True,\n",
    ")\n",
    "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\"gpt2_base_en\", preprocessor=gpt2_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "output = gpt2_lm.generate(\"My trip to Yosemite was\", max_length=200)\n",
    "print(\"\\nGPT-2 output:\")\n",
    "print(output.numpy().decode(\"utf-8\"))\n",
    "\n",
    "end = time.time()\n",
    "print(\"TOTAL TIME ELAPSED: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "output = gpt2_lm.generate(\"That Italian restaurant is\", max_length=200)\n",
    "print(\"\\nGPT-2 output:\")\n",
    "print(output.numpy().decode(\"utf-8\"))\n",
    "\n",
    "end = time.time()\n",
    "print(\"TOTAL TIME ELAPSED: \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune on Startup Interviews by Glavin001\n",
    "\n",
    "- preprocess the dataset\n",
    "- finetune the model\n",
    "- save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "raw_dataset = load_dataset(\"Glavin001/startup-interviews\")\n",
    "\n",
    "end = time.time()\n",
    "print(\"TOTAL TIME ELAPSED: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_dataset.remove_columns(['input', 'start', 'instruction_length', 'output_length', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train'].select(range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "all_sentences = []\n",
    "count = 0\n",
    "total = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sentences(first_s, second_s):\n",
    "  return first_s + \" : \" + second_s\n",
    "\n",
    "raw_sentences = list(map(merge_sentences, dataset['instruction'], dataset['output']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sentences[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_sentences in raw_sentences:\n",
    "  # Use NLTK tokenize to split sentences into sentences\n",
    "  sentences = tokenize.sent_tokenize(str(raw_sentences))\n",
    "  # If it exceed max_length, trim the tails.\n",
    "  if len(sentences) > max_length:\n",
    "    sentences = sentences[:max_length]\n",
    "  # Add merged context into collection\n",
    "  all_sentences.extend(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_ds = tf.data.Dataset.from_tensor_slices(all_sentences)\n",
    "processed_ds = tf_train_ds.map(gpt2_preprocessor, tf.data.AUTOTUNE).batch(4).cache().prefetch(tf.data.AUTOTUNE)\n",
    "part_of_ds = processed_ds.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_lm.include_preprocessing = False\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "lr = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    5e-5,\n",
    "    decay_steps=part_of_ds.cardinality() * num_epochs,\n",
    "    end_learning_rate=0.00002,\n",
    ")\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "gpt2_lm.compile(\n",
    "    optimizer=keras.optimizers.experimental.Adam(lr),\n",
    "    loss=loss,\n",
    "    weighted_metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "gpt2_lm.fit(part_of_ds, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "output = gpt2_lm.generate(\"How do you determine the effectiveness of implementing suggested changes in a startup?\", max_length=200)\n",
    "print(\"\\nGPT-2 output:\")\n",
    "print(output.numpy().decode(\"utf-8\"))\n",
    "\n",
    "end = time.time()\n",
    "print(\"TOTAL TIME ELAPSED: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_lm.backbone.save_weights(\"finetuned_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gpt2_tokenizer, gpt2_preprocessor, gpt2_lm"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
